import streamlit as st 
import os
from datetime import datetime
from fact_checker_v4_english import FactChecker
import time

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="AIè™šå‡æ–°é—»æ£€æµ‹å™¨",
    page_icon="ğŸ”",
    layout="wide",
    menu_items={
        'Get Help': None,
        'Report a bug': None,
        'About': None
    }
)

# åº”ç”¨æ ‡é¢˜å’Œæè¿°
st.title("AIè™šå‡æ–°é—»æ£€æµ‹å™¨")
st.markdown("""
æœ¬åº”ç”¨ç¨‹åºä½¿ç”¨APIè°ƒç”¨LLMéªŒè¯é™ˆè¿°çš„å‡†ç¡®æ€§ã€‚
è¯·åœ¨ä¸‹æ–¹è¾“å…¥éœ€è¦æ ¸æŸ¥çš„æ–°é—»ï¼Œç³»ç»Ÿå°†æ£€ç´¢ç½‘ç»œè¯æ®è¿›è¡Œæ–°é—»æ ¸æŸ¥ï¼Œæ— ç½‘ç»œæ—¶å°†åªè¿›è¡Œæœ¬åœ°çŸ¥è¯†åº“æ£€ç´¢ã€‚
""")

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.header("é…ç½®")
    
    # æœ¬åœ°APIç«¯ç‚¹è®¾ç½®
    api_base = st.text_input("APIåŸºç¡€URL", value="https://dashscope.aliyuncs.com/compatible-mode/v1", 
                             help="æ‚¨çš„æœ¬åœ°APIç«¯ç‚¹çš„åŸºç¡€URL")
    
    # æ¨¡å‹é€‰æ‹© - å·²æ›´æ–°ä¸ºæœ¬åœ°Qwenæ¨¡å‹
    model_option = st.selectbox(
        "é€‰æ‹©æ¨¡å‹",
        ["qwen2.5-14b-instruct-1m"],  # ä½ å¯ä»¥æ‰©å±•æ›´å¤šæ¨¡å‹é€‰é¡¹
        index=0,
        help="ä½¿ç”¨æœ¬åœ°Qwen2.5æ¨¡å‹"
    )
    
    # é«˜çº§è®¾ç½®æŠ˜å éƒ¨åˆ†
    with st.expander("é«˜çº§è®¾ç½®"):
        temperature = st.slider("æ¸©åº¦", min_value=0.0, max_value=1.0, value=0.0, step=0.1, 
                               help="è¾ƒä½çš„å€¼ä½¿å“åº”æ›´ç¡®å®šï¼Œè¾ƒé«˜çš„å€¼ä½¿å“åº”æ›´å…·åˆ›é€ æ€§")
        max_tokens = st.slider("æœ€å¤§å“åº”é•¿åº¦", min_value=100, max_value=8000, value=1000, step=100,
                              help="å“åº”ä¸­çš„æœ€å¤§æ ‡è®°æ•°")
    
    st.divider()
    st.markdown("### å…³äº ###")
    st.markdown("è™šå‡æ–°é—»æ£€æµ‹å™¨:")
    st.markdown("1. ä»æ–°é—»ä¸­æå–æ ¸å¿ƒå£°æ˜")
    st.markdown("2. åœ¨ç½‘ç»œä¸Šå’Œæœ¬åœ°åº“æœç´¢è¯æ®")
    st.markdown("3. ä½¿ç”¨BGE-M3æŒ‰ç›¸å…³æ€§å¯¹è¯æ®è¿›è¡Œæ’å")
    st.markdown("4. åŸºäºè¯æ®æä¾›ç»“è®º")
    st.markdown("ä½¿ç”¨LLMã€Streamlitã€BGE-M3å’Œragå¼€å‘ â¤ï¸â¤ï¸â¤ï¸")

# å¦‚æœä¸å­˜åœ¨ï¼Œåˆå§‹åŒ–ä¼šè¯çŠ¶æ€ä»¥å­˜å‚¨èŠå¤©å†å²
if 'messages' not in st.session_state:
    st.session_state.messages = []

# æ˜¾ç¤ºèŠå¤©å†å²
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# ä¸»è¾“å…¥åŒºåŸŸ
user_input = st.chat_input("è¯·åœ¨ä¸‹æ–¹è¾“å…¥éœ€è¦æ ¸æŸ¥çš„æ–°é—»...")

if user_input:
    # å°†ç”¨æˆ·æ¶ˆæ¯æ·»åŠ åˆ°èŠå¤©å†å²
    st.session_state.messages.append({"role": "user", "content": user_input})
    
    # æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
    with st.chat_message("user"):
        st.markdown(user_input)
    
    # ä½¿ç”¨ with ä¸Šä¸‹æ–‡åˆ›å»ºåŠ©æ‰‹æ¶ˆæ¯å®¹å™¨
    with st.chat_message("assistant"):
        # åˆ›å»ºå¤šä¸ªç‹¬ç«‹å ä½ç¬¦ï¼Œé¿å… DOM é”™è¯¯
        claim_placeholder = st.empty()
        information_placeholder = st.empty()
        evidence_placeholder = st.empty()
        verdict_placeholder = st.empty()

        # åˆå§‹åŒ–FactChecker
        fact_checker = FactChecker(api_base, model_option, temperature, max_tokens)

        # ç¬¬1æ­¥ï¼šæå–å£°æ˜
        claim_placeholder.markdown("### ğŸ” æ­£åœ¨æå–æ–°é—»çš„æ ¸å¿ƒå£°æ˜...")
        claim = fact_checker.extract_claim(user_input)

        # å¤„ç†claimå­—ç¬¦ä¸²ï¼Œæå–"claim:"åé¢çš„å†…å®¹
        if "claim:" in claim.lower():
            claim = claim.split("claim:")[-1].strip()
        claim_placeholder.markdown(f"### ğŸ” æå–æ–°é—»çš„æ ¸å¿ƒå£°æ˜\n\n{claim}")

        # æå–å…³é”®ä¿¡æ¯
        information_placeholder.markdown("### ğŸ” æ­£åœ¨æå–æ–°é—»çš„å…³é”®ä¿¡æ¯...")
        information = fact_checker.extract_keyinformation(user_input)
        information_placeholder.markdown(f"### ğŸ” æå–æ–°é—»çš„å…³é”®ä¿¡æ¯\n\n{information}")

        # ç¬¬2æ­¥ï¼šæœç´¢è¯æ®
        evidence_placeholder.markdown("### ğŸŒ æ­£åœ¨æœç´¢ç›¸å…³è¯æ®...")
        evidence_docs = fact_checker.search_evidence(claim)

        # ç¬¬3æ­¥ï¼šè·å–ç›¸å…³è¯æ®å—
        evidence_placeholder.markdown("### ğŸŒ æ­£åœ¨åˆ†æè¯æ®ç›¸å…³æ€§...")
        evidence_chunks = fact_checker.get_evidence_chunks(evidence_docs, claim)

        # æ˜¾ç¤ºè¯æ®ç»“æœ
        evidence_md = "### ğŸ”— è¯æ®æ¥æº\n\n"
        for j, chunk in enumerate(evidence_chunks[:-1]):  # è·³è¿‡æœ€åä¸€ä¸ªï¼Œä¸åŸå§‹ä»£ç ä¿æŒä¸€è‡´
            evidence_md += f"**[{j+1}]:**\n"
            evidence_md += f"{chunk['text']}\n"
            evidence_md += f"æ¥æº: {chunk['source']}\n\n"
        evidence_placeholder.markdown(evidence_md)

        # ç¬¬4æ­¥ï¼šè¯„ä¼°å£°æ˜
        verdict_placeholder.markdown("### âš–ï¸ æ­£åœ¨è¯„ä¼°å£°æ˜çœŸå®æ€§...")
        evaluation = fact_checker.evaluate_claim(information, user_input, evidence_chunks)

        # ç¡®å®šç»“è®ºè¡¨æƒ…ç¬¦å·
        verdict = evaluation["verdict"]
        if verdict.upper() == "TRUE":
            emoji = "âœ…"
            verdict_cn = "æ­£ç¡®"
        elif verdict.upper() == "FALSE":
            emoji = "âŒ"
            verdict_cn = "é”™è¯¯"
        elif verdict.upper() == "PARTIALLY TRUE":
            emoji = "âš ï¸"
            verdict_cn = "éƒ¨åˆ†æ­£ç¡®"
        else:
            emoji = "â“"
            verdict_cn = "æ— æ³•éªŒè¯"

        # æ˜¾ç¤ºæœ€ç»ˆç»“è®º
        verdict_md = f"### {emoji} ç»“è®º: {verdict_cn}\n\n"
        verdict_md += f"### æ¨ç†è¿‡ç¨‹\n\n{evaluation['reasoning']}\n\n"

        verdict_placeholder.markdown(verdict_md)

        # æ•´åˆå®Œæ•´çš„å“åº”å†…å®¹ç”¨äºä¿å­˜åˆ°èŠå¤©å†å²
        full_response = f"""
### ğŸ” æå–æ–°é—»çš„æ ¸å¿ƒå£°æ˜

{claim}

---

{information}

---

{evidence_md}

---

{verdict_md}
"""

        # æ·»åŠ åŠ©æ‰‹å“åº”åˆ°èŠå¤©å†å²
        st.session_state.messages.append({"role": "assistant", "content": full_response})
